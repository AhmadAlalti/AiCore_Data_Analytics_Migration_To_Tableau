{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV files into a pandas dataframe\n",
    "\n",
    "Create a function that takes a path to a CSV file as anargument and returns a pandas dataframe. This function loops through the CSV files in the path and creates a pandas dataframe for each file with the dataframe name as the CSV file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_df(csv_directory_path):\n",
    "    dfs = {}\n",
    "    print('-' * 150)\n",
    "    print('Now converting csv files to dataframes...')\n",
    "    print('-' * 150)\n",
    "    for csv_file in glob.glob(csv_directory_path + '/*.csv'):\n",
    "        print(f'Working on {csv_file} ...')\n",
    "        print('Converting to dataframe...')\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print('Done... Now Getting filename...')\n",
    "        filename = csv_file.split('/')[-1].replace('.csv', '')\n",
    "        print('Done... Renaming dataframe...')\n",
    "        exec(f\"dfs['df_{filename}'] = df\")\n",
    "    print('-' * 150)\n",
    "    print('Done converting csv files to dataframes...')\n",
    "    return dfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = convert_csv_to_df('data-analytics-files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the dictionary of dataframes based on key names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()\n",
    "sorted_keys = sorted(dfs.keys())\n",
    "dfs_sorted = {key: dfs[key] for key in sorted_keys}\n",
    "dfs_sorted.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Create a function that takes in a dataframe as an argument. The function counts the null values in each column and then finds the columns where all the values are null. These columns are then removed from the dataframe. A second check for null values is performed to see if there are any columns where all the values are null in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_delete_nulls(df):\n",
    "    num_rows = df.shape[0]\n",
    "    print(f'This dataframe contains {num_rows} rows')\n",
    "    print('Counting nulls in dataframe')\n",
    "    null_count = pd.isna(df).sum()\n",
    "    print(null_count)\n",
    "    all_nan_cols = df.columns[df.isna().all()]\n",
    "    print(all_nan_cols)\n",
    "    print('Dropping nulls columns in dataframe')\n",
    "    df.drop(columns=all_nan_cols, axis=1, inplace=True)\n",
    "    print('Checking for any other columns with all null values')\n",
    "    print(df.columns[df.isna().all()])\n",
    "    print('Done')\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function and returning the resulting dataframes into a list in order to concatenate them into a single dataframe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_list = []\n",
    "for df_name, df_value in dfs_sorted.items():\n",
    "    print('-' * 150)\n",
    "    print(f'Working on {df_name}')\n",
    "    print('-' * 150)\n",
    "    df = count_and_delete_nulls(df_value)\n",
    "    dfs_list.append(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are counting the number of rows in each dataframe and the number of nulls in each column. Following this we are counting the number of nulls in total then filling these values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dfs_list = []\n",
    "for df in dfs_list:\n",
    "    num_rows = df.shape[0]\n",
    "    print(f'This dataframe contains {num_rows} rows')\n",
    "    null_count = df.isna().sum()\n",
    "    if null_count.any():\n",
    "        print(f'This dataframe contains null values in some columns')\n",
    "        null_count_all = df.isna().sum().sum()\n",
    "        print(f' In total, this dataframe contains {null_count_all} null values')\n",
    "    else:\n",
    "        print(f'This dataframe does not contain null values in any of the columns')\n",
    "    print(f'Filling these null values in the dataframe with 0s')\n",
    "    df.fillna(0, inplace=True)\n",
    "    clean_dfs_list.append(df)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block of code we are exploring the columns remaining in each of the dataframes. Some dataframes have the same columns but some have additional columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in clean_dfs_list:\n",
    "    print('Checking the columns of the dataframe:')\n",
    "    columns = df.columns.to_list()\n",
    "    print(columns)\n",
    "    columns_total = len(columns)\n",
    "    print(f'In total there are {columns_total} columns in the dataframe.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration\n",
    "\n",
    "Now, we are integratng the dataframes into one merged dataframe. We then count the number of rows and check if the resulting dataframe contains null values as some columns didn't exist in the original individual dataframes. These null values are then filled with 0s. Following this we export the resulting dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Concatenating the dataframes together...')\n",
    "df = pd.concat(clean_dfs_list).reset_index(drop=True)\n",
    "num_rows = df.shape[0]\n",
    "print(f'Number of rows: {num_rows}')\n",
    "print('Counting the null values in the combined dataframe...')\n",
    "for col in df.columns:\n",
    "    null_count = df[col].isnull().sum()\n",
    "    print(f'{col}: {null_count} null values')\n",
    "print('Filling the null values in the combined dataframe with 0s...')\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# print('Saving the combined dataframe...')\n",
    "# df.to_csv('combined_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we explore the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.columns\n",
    "df.info()\n",
    "df['ArrDelay'].info()\n",
    "value = 'SAN'\n",
    "position = np.where(df.values == value)\n",
    "print(position)\n",
    "df.head().to_csv('data.csv', index=False)\n",
    "df['ArrDelay'].head()\n",
    "df.tail().to_csv('data2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
